{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from pandas import json_normalize\n",
        "\n",
        "INPUT_FILE = \"14112025_BANK_PNL.txt\"     # your pasted file\n",
        "OUTPUT_CSV = \"flattened_snapshots.csv\"\n",
        "\n",
        "\n",
        "def parse_snapshot(obj):\n",
        "    \"\"\"\n",
        "    Flatten one snapshot including nested Current, Previous, Next JSON blocks.\n",
        "    \"\"\"\n",
        "    flat = {}\n",
        "\n",
        "    # 1. Copy all top-level fields except 'Current'\n",
        "    for k, v in obj.items():\n",
        "        if k != \"Current\":\n",
        "            flat[k] = v\n",
        "\n",
        "    # 2. Parse nested Current JSON string safely\n",
        "    if \"Current\" in obj:\n",
        "        try:\n",
        "            curr = json.loads(obj[\"Current\"])\n",
        "        except Exception:\n",
        "            curr = {}\n",
        "\n",
        "        # Process Previous, Current, Next inside\n",
        "        for section_name in [\"Previous\", \"Current\", \"Next\"]:\n",
        "            if section_name in curr and isinstance(curr[section_name], dict):\n",
        "                for key, val in curr[section_name].items():\n",
        "                    flat[f\"{section_name}_{key}\"] = val\n",
        "            else:\n",
        "                # Add empty if missing\n",
        "                flat[f\"{section_name}\"] = None\n",
        "\n",
        "    return flat\n",
        "\n",
        "\n",
        "def load_snapshots(path):\n",
        "    \"\"\"\n",
        "    Load file that contains:\n",
        "    - either JSON objects separated by newlines\n",
        "    - or multiple JSON blobs one after another\n",
        "    \"\"\"\n",
        "    snapshots = []\n",
        "    with open(path, \"r\") as f:\n",
        "        raw = f.read().strip()\n",
        "\n",
        "    # Try line-by-line JSON parsing\n",
        "    for line in raw.splitlines():\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "        try:\n",
        "            snapshots.append(json.loads(line))\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    # If nothing loaded, try parsing entire file as list\n",
        "    if len(snapshots) == 0:\n",
        "        try:\n",
        "            snapshots = json.loads(raw)\n",
        "        except:\n",
        "            raise ValueError(\"Cannot parse file: Format looks invalid\")\n",
        "\n",
        "    return snapshots\n",
        "\n",
        "\n",
        "def main():\n",
        "    snapshots = load_snapshots(INPUT_FILE)\n",
        "    print(f\"Loaded snapshots: {len(snapshots)}\")\n",
        "\n",
        "    # Flatten all snapshots\n",
        "    flattened = [parse_snapshot(snap) for snap in snapshots]\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    df = pd.DataFrame(flattened)\n",
        "\n",
        "    # Normalize types\n",
        "    for col in df.columns:\n",
        "        # Clean array strings \"[]\"\n",
        "        df[col] = df[col].apply(lambda x: None if x == \"[]\" else x)\n",
        "\n",
        "    # Convert timestamp\n",
        "    if \"LTT\" in df.columns:\n",
        "        df[\"LTT\"] = pd.to_datetime(df[\"LTT\"], errors=\"coerce\")\n",
        "\n",
        "    # Save to CSV\n",
        "    df.to_csv(OUTPUT_CSV, index=False)\n",
        "    print(f\"Saved: {OUTPUT_CSV}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUkkvJ2pNFZJ",
        "outputId": "70d0719f-1765-43b1-d01e-88f1f0eb7eca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded snapshots: 22300\n",
            "Saved: flattened_snapshots.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iUL7dK4MoQ1",
        "outputId": "fa731447-90dc-40fa-bf86-7ae36ba5b484"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated FULL_STRIKE_FORECAST_OUTPUT.csv successfully!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import defaultdict, Counter\n",
        "from datetime import timedelta\n",
        "\n",
        "# ============================================================\n",
        "# LOAD CSV\n",
        "# ============================================================\n",
        "df = pd.read_csv(\"flattened_snapshots.csv\", low_memory=False, parse_dates=['LTT'])\n",
        "\n",
        "# Detect which premium column exists\n",
        "prev_p = \"Previous_Call_Premium\" if \"Previous_Call_Premium\" in df else \"Previous_Call_ltp\"\n",
        "curr_p = \"Current_Call_Premium\"  if \"Current_Call_Premium\"  in df else \"Current_Call_ltp\"\n",
        "next_p = \"Next_Call_Premium\"     if \"Next_Call_Premium\"     in df else \"Next_Call_ltp\"\n",
        "\n",
        "prev_str, curr_str, next_str = \"Previous_Strikeprice\",\"Current_Strikeprice\",\"Next_Strikeprice\"\n",
        "\n",
        "# ============================================================\n",
        "# BUILD STRIKE â†’ (timestamp, premium) TIMESERIES\n",
        "# ============================================================\n",
        "strike_series = defaultdict(list)\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    t = row[\"LTT\"]\n",
        "    for sc, pc in [(prev_str, prev_p), (curr_str, curr_p), (next_str, next_p)]:\n",
        "        if sc in row and pc in row and not pd.isna(row[sc]) and not pd.isna(row[pc]):\n",
        "            try:\n",
        "                s = int(row[sc])\n",
        "                p = float(row[pc])\n",
        "                strike_series[s].append((t, p))\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "# ============================================================\n",
        "# SUMMARY + FORECAST FUNCTIONS\n",
        "# ============================================================\n",
        "def summarize(series):\n",
        "    sr = sorted(series, key=lambda x: x[0])\n",
        "    ps = [p for _, p in sr]\n",
        "\n",
        "    if not ps:\n",
        "        return None\n",
        "\n",
        "    first, last = ps[0], ps[-1]\n",
        "    peak, trough = max(ps), min(ps)\n",
        "    pct = ((last-first)/first*100) if first != 0 else 0\n",
        "\n",
        "    return {\n",
        "        \"first_premium\": first,\n",
        "        \"last_premium\": last,\n",
        "        \"peak_premium\": peak,\n",
        "        \"trough_premium\": trough,\n",
        "        \"abs_change\": last - first,\n",
        "        \"pct_change\": pct,\n",
        "        \"n_obs\": len(ps)\n",
        "    }\n",
        "\n",
        "def forecast(stats):\n",
        "    pct = stats[\"pct_change\"]\n",
        "    last = stats[\"last_premium\"]\n",
        "\n",
        "    if pct >= 25:\n",
        "        return (last+15, last+35), (last+25, last+60)\n",
        "    elif pct >= 8:\n",
        "        return (last+6, last+18), (last+12, last+30)\n",
        "    elif pct > 0:\n",
        "        return (last+2, last+8), (last+5, last+15)\n",
        "    else:\n",
        "        return (last-5, last+2), (last-8, last+5)\n",
        "\n",
        "# ============================================================\n",
        "# BUILD SUMMARY FOR ALL STRIKES\n",
        "# ============================================================\n",
        "records = []\n",
        "\n",
        "for s, ts in strike_series.items():\n",
        "    if len(ts) < 3:\n",
        "        continue\n",
        "\n",
        "    st = summarize(ts)\n",
        "    if st is None:\n",
        "        continue\n",
        "\n",
        "    f5, f10 = forecast(st)\n",
        "\n",
        "    rec = {\n",
        "        \"strike\": s,\n",
        "        **st,\n",
        "        \"5min_low\":  f5[0],\n",
        "        \"5min_high\": f5[1],\n",
        "        \"10min_low\": f10[0],\n",
        "        \"10min_high\": f10[1],\n",
        "        \"p5_expected_lo\": f5[0] - st[\"last_premium\"],\n",
        "        \"p5_expected_hi\": f5[1] - st[\"last_premium\"],\n",
        "        \"p10_expected_lo\": f10[0] - st[\"last_premium\"],\n",
        "        \"p10_expected_hi\": f10[1] - st[\"last_premium\"]\n",
        "    }\n",
        "\n",
        "    records.append(rec)\n",
        "\n",
        "summary = pd.DataFrame(records)\n",
        "\n",
        "# ============================================================\n",
        "# STRATEGY TAGS + MONEYFLOW EXTRACTION\n",
        "# ============================================================\n",
        "tag_keywords = [\n",
        "    \"RSI\", \"MACD\", \"VWAP\", \"RSI_MACD\", \"VWAP_Divergence\", \"OI_Support_Call\",\n",
        "    \"Put Buying\", \"Call Writing\", \"PnL\", \"Momentum\", \"Breakout\"\n",
        "]\n",
        "\n",
        "strike_info = {\n",
        "    int(s): {\n",
        "        \"tags\": Counter(),\n",
        "        \"call_moneyflow\": 0.0,\n",
        "        \"put_moneyflow\": 0.0\n",
        "    }\n",
        "    for s in summary[\"strike\"]\n",
        "}\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    for sc in [prev_str, curr_str, next_str]:\n",
        "        if sc in row and not pd.isna(row[sc]):\n",
        "            try:\n",
        "                s = int(row[sc])\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "            if s not in strike_info:\n",
        "                continue\n",
        "\n",
        "            # Extract tags\n",
        "            for col in [\"Previous_StrategyTag\", \"Current_StrategyTag\", \"Next_StrategyTag\"]:\n",
        "                if col in df and isinstance(row.get(col), str):\n",
        "                    for kw in tag_keywords:\n",
        "                        if kw.lower() in row[col].lower():\n",
        "                            strike_info[s][\"tags\"][kw] += 1\n",
        "\n",
        "            # Moneyflow\n",
        "            for col in [\n",
        "                \"Previous_CallMoneyFlow\",\"Current_CallMoneyFlow\",\"Next_CallMoneyFlow\",\n",
        "                \"Previous_PutMoneyFlow\",\"Current_PutMoneyFlow\",\"Next_PutMoneyFlow\"\n",
        "            ]:\n",
        "                if col in df and not pd.isna(row.get(col)):\n",
        "                    val = float(row[col])\n",
        "                    if \"Call\" in col:\n",
        "                        strike_info[s][\"call_moneyflow\"] += val\n",
        "                    else:\n",
        "                        strike_info[s][\"put_moneyflow\"] += val\n",
        "\n",
        "# ============================================================\n",
        "# HIGH CONVICTION SIGNAL HIT RATE\n",
        "# ============================================================\n",
        "highconv_col = \"Current_IsHighConvictionSignal\"\n",
        "\n",
        "# ============================================================\n",
        "# BUILD FINAL OUTPUT\n",
        "# ============================================================\n",
        "final_rows = []\n",
        "\n",
        "for _, r in summary.iterrows():\n",
        "    s = int(r[\"strike\"])\n",
        "    info = strike_info[s]\n",
        "\n",
        "    # Build reasoning text\n",
        "    tags = info[\"tags\"]\n",
        "    reasons = []\n",
        "\n",
        "    if tags.get(\"RSI\",0) or tags.get(\"RSI_MACD\",0):\n",
        "        reasons.append(\"RSI/MACD bullish pattern\")\n",
        "    if tags.get(\"VWAP_Divergence\",0):\n",
        "        reasons.append(\"VWAP divergence support\")\n",
        "    if tags.get(\"OI_Support_Call\",0):\n",
        "        reasons.append(\"OI call support detected\")\n",
        "    if tags.get(\"Put Buying\",0):\n",
        "        reasons.append(\"Put side hedging activity\")\n",
        "\n",
        "    if not reasons:\n",
        "        reasons.append(\"No strong signals\")\n",
        "\n",
        "    # Recommended Action\n",
        "    if r[\"pct_change\"] > 5:\n",
        "        act = \"BUY_CALL\"\n",
        "    elif r[\"pct_change\"] < -5:\n",
        "        act = \"BUY_PUT\"\n",
        "    else:\n",
        "        act = \"HOLD\"\n",
        "\n",
        "    # High-conviction stats\n",
        "    hc_rows = df[(df[curr_str]==s) & (df.get(highconv_col)==True)]\n",
        "    hc_total = hc_rows.shape[0]\n",
        "    hc_success = 0\n",
        "\n",
        "    for _, row2 in hc_rows.iterrows():\n",
        "        t0 = row2[\"LTT\"]\n",
        "        p0 = row2[curr_p]\n",
        "\n",
        "        window = df[\n",
        "            (df[\"LTT\"] >= t0) &\n",
        "            (df[\"LTT\"] <= t0 + timedelta(minutes=3)) &\n",
        "            (df[curr_str] == s)\n",
        "        ]\n",
        "\n",
        "        if not window.empty:\n",
        "            if window[curr_p].max() > p0:\n",
        "                hc_success += 1\n",
        "\n",
        "    final_rows.append({\n",
        "        **r.to_dict(),\n",
        "        \"call_moneyflow\": info[\"call_moneyflow\"],\n",
        "        \"put_moneyflow\": info[\"put_moneyflow\"],\n",
        "        \"tags\": \";\".join([f\"{k}:{v}\" for k,v in tags.items()]),\n",
        "        \"reasons\": \"; \".join(reasons),\n",
        "        \"recommended_action\": act,\n",
        "        \"highconv_total\": hc_total,\n",
        "        \"highconv_success\": hc_success,\n",
        "        \"highconv_hit_rate\": (hc_success / hc_total) if hc_total > 0 else None,\n",
        "        \"Current_Strikeprice\": s\n",
        "    })\n",
        "\n",
        "final_df = pd.DataFrame(final_rows)\n",
        "\n",
        "# SAVE OUTPUT\n",
        "final_df.to_csv(\"FULL_STRIKE_FORECAST_OUTPUT.csv\", index=False)\n",
        "print(\"Generated FULL_STRIKE_FORECAST_OUTPUT.csv successfully!\")\n"
      ]
    }
  ]
}